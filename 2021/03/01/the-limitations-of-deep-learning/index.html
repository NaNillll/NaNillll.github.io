<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta name="google-site-verification" content="kWcVT9oyylmyb6DohoXWge7VpBUZQVIptcOSS5Gr9wc" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Machine Learning,Deep Learning," />










<meta name="description" content="limitationshttps:&#x2F;&#x2F;blog.keras.io&#x2F;the-limitations-of-deep-learning.html Deep learning: the geometric viewIn deep learning, everything is a vector, i.e. everything is a point in a geometric space.  Toge">
<meta property="og:type" content="article">
<meta property="og:title" content="limitations and future of deep learning">
<meta property="og:url" content="http://yoursite.com/2021/03/01/the-limitations-of-deep-learning/index.html">
<meta property="og:site_name" content="The Grimoire of NaNillll">
<meta property="og:description" content="limitationshttps:&#x2F;&#x2F;blog.keras.io&#x2F;the-limitations-of-deep-learning.html Deep learning: the geometric viewIn deep learning, everything is a vector, i.e. everything is a point in a geometric space.  Toge">
<meta property="article:published_time" content="2021-03-01T03:21:46.000Z">
<meta property="article:modified_time" content="2021-03-02T01:24:32.079Z">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2021/03/01/the-limitations-of-deep-learning/"/>





  <title>limitations and future of deep learning | The Grimoire of NaNillll</title>
  








<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">The Grimoire of NaNillll</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/01/the-limitations-of-deep-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="The Grimoire of NaNillll">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">limitations and future of deep learning</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-03-01T11:21:46+08:00">
                2021-03-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="limitations"><a href="#limitations" class="headerlink" title="limitations"></a>limitations</h1><p><a href="https://blog.keras.io/the-limitations-of-deep-learning.html" target="_blank" rel="noopener">https://blog.keras.io/the-limitations-of-deep-learning.html</a></p>
<h2 id="Deep-learning-the-geometric-view"><a href="#Deep-learning-the-geometric-view" class="headerlink" title="Deep learning: the geometric view"></a>Deep learning: the geometric view</h2><p>In deep learning, everything is a vector, i.e. everything is a <em>point</em> in a <em>geometric space</em>. </p>
<p>Together, the chain of layers of the model forms one very complex geometric transformation</p>
<p>This complex transformation attempts to maps the input space to the target space</p>
<p>A key characteristic of this geometric transformation is that it must be <em>differentiable</em>, which is required in order for us to be able to learn its parameters via gradient descent</p>
<p>总而言之，这就是将高维数据的复杂流形解压的过程，就像把一个揉皱的纸球解开弄平一样</p>
<h2 id="The-limitations-of-deep-learning"><a href="#The-limitations-of-deep-learning" class="headerlink" title="The limitations of deep learning"></a>The limitations of deep learning</h2><p>The space of applications that can be implemented with this simple strategy is nearly infinite</p>
<p> In general, anything that requires reasoning—like programming, or applying the scientific method—long-term planning, and algorithmic-like data manipulation, is out of reach for deep learning models— Even learning a sorting algorithm with a deep neural network is tremendously difficult.</p>
<p>This is because a deep learning model is “just” <em>a chain of simple, continuous geometric transformations</em> mapping one vector space into another</p>
<p>most programs cannot be expressed as deep learning models</p>
<p>most of the programs that one may wish to learn cannot be expressed as a continuous geometric morphing of a data manifold</p>
<h2 id="The-risk-of-anthropomorphizing-machine-learning-models"><a href="#The-risk-of-anthropomorphizing-machine-learning-models" class="headerlink" title="The risk of anthropomorphizing machine learning models"></a>The risk of anthropomorphizing machine learning models</h2><p>One very real risk with contemporary AI is that of misinterpreting what deep learning models do, and overestimating their abilities</p>
<p> A fundamental feature of the human mind is our “theory of mind”, our tendency to project intentions, beliefs and knowledge on the things around us</p>
<p>In particular, this is highlighted by “adversarial examples”, which are input samples to a deep learning network that are designed to trick the model into misclassifying them</p>
<p>By taking a picture of a panda and adding to it a “gibbon” gradient, we can get a neural network to classify this panda as a gibbon</p>
<p>In short, deep learning models do not have any understanding of their input, at least not in any human sense</p>
<p>never fall into the trap of believing that neural networks understand the task they perform they don’t, at least not in a way that would make sense to us</p>

<h2 id="Local-generalization-versus-extreme-generalization"><a href="#Local-generalization-versus-extreme-generalization" class="headerlink" title="Local generalization versus extreme generalization"></a>Local generalization versus extreme generalization</h2><p>This ability to handle hypotheticals, to expand our mental model space far beyond what we can experience directly, in a word, to perform <em>abstraction</em> and <em>reasoning</em>, is arguably the defining characteristic of human cognition— I call it “extreme generalization”: an ability to adapt to novel, never experienced before situations, using very little data or even no new data at all.</p>
<p>This stands in sharp contrast with what deep nets do, which I would call “local generalization”: the mapping from inputs to outputs performed by deep nets quickly stops making sense if new inputs differ even slightly from what they saw at training time. </p>
<p>人类有抽象建模能力，但是深度网络不行。如果想要训练在某个城市里自动驾驶的深度网络，可能需要出成千上百次错误，而换一个城市，这个网络就可能出现问题——但是人类不会</p>

<h2 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h2><p>To lift some of these limitations and start competing with human brains, we need to move away from straightforward input-to-output mappings, and on to <em>reasoning</em> and <em>abstraction</em>. </p>
<h1 id="future"><a href="#future" class="headerlink" title="future"></a>future</h1><p><a href="https://blog.keras.io/the-future-of-deep-learning.html" target="_blank" rel="noopener">https://blog.keras.io/the-future-of-deep-learning.html</a></p>
<h2 id="main-directions"><a href="#main-directions" class="headerlink" title="main directions"></a>main directions</h2><ul>
<li>Models closer to general-purpose computer programs, built on top of far richer primitives than our current differentiable layers—this is how we will get to <em>reasoning</em> and <em>abstraction</em>, the fundamental weakness of current models</li>
<li>New forms of learning that make the above possible—allowing models to move away from just differentiable transforms.</li>
<li>Models that require less involvement from human engineers—it shouldn’t be your job to tune knobs endlessly.</li>
<li>Greater, systematic reuse of previously learned features and architectures; meta-learning systems based on reusable and modular program subroutines.</li>
</ul>
<h2 id="Models-as-programs"><a href="#Models-as-programs" class="headerlink" title="Models as programs"></a>Models as programs</h2><p>a move away from models that perform purely <em>pattern recognition</em> and can only achieve <em>local generalization</em>, towards models capable of <em>abstraction</em> and <em>reasoning</em>, that can achieve <em>extreme generalization</em></p>
<p> In DeepMind’s AlphaGo, for example, most of the “intelligence” on display is designed and hard-coded by expert programmers (e.g. Monte-Carlo tree search); learning from data only happens in specialized submodules (value networks and policy networks). But in the future, such AI systems may well be fully learned, with no human involvement</p>
<p>例如RNN，不是简单的只用一个for，而是使用大量的编程原语，模型可以自由操作，以扩展其处理功能，如if分支、while语句、变量创建、长期内存磁盘存储、排序操作符、高级数据结构(如列表、图和哈希表)等等</p>
<p>  A big way is <em>program synthesis</em>， The difference is that instead of learning parameter values in a hard-coded program (a neural network), we generate <em>source code</em> via a discrete search process.</p>
<p>深度学习和program synthesis之间可能出现一个交叉子域，不会直接生成通用的编程语言编写的程序，而是生成神经网络，并通过for等编程原语来增强</p>
<h2 id="Beyond-backpropagation-and-differentiable-layers"><a href="#Beyond-backpropagation-and-differentiable-layers" class="headerlink" title="Beyond backpropagation and differentiable layers"></a>Beyond backpropagation and differentiable layers</h2><p>If machine learning models become more like programs, then they will mostly no longer be differentiable</p>
<p>We need to figure out to train non-differentiable systems efficiently. Current approaches include genetic algorithms, “evolution strategies”, certain reinforcement learning methods, and ADMM (alternating direction method of multipliers)</p>
<h2 id="Automated-machine-learning"><a href="#Automated-machine-learning" class="headerlink" title="Automated machine learning"></a>Automated machine learning</h2><p> Learning architectures automatically goes hand in hand with the use of richer sets of primitives and program-like machine learning models.</p>
<p>Unfortunately, the data munging part is tough to automate, since it often requires domain knowledge as well as a clear high-level understanding of what the engineer wants to achieve.</p>
<p>At the most basic level, such a system would simply tune the number of layers in a stack, their order, and the number of units or filters in each layer. </p>
<p>Another important AutoML direction is to learn model architecture jointly with model weights</p>
<h2 id="Lifelong-learning-and-modular-subroutine-reuse"><a href="#Lifelong-learning-and-modular-subroutine-reuse" class="headerlink" title="Lifelong learning and modular subroutine reuse"></a>Lifelong learning and modular subroutine reuse</h2><p>If models get more complex and are built on top of richer algorithmic primitives, then this increased complexity will require higher reuse between tasks</p>
<p>Much like you don’t learn English from scratch every time you open a new book—that would be impossible. </p>
<p>我们不仅会利用以前学习的功能（子模型权重），还会利用模型架构和训练过程。 随着模型变得更像程序，我们将开始重用程序子程序，例如人类编程语言中的函数和类</p>
<p>想想当今的软件开发过程：工程师解决了特定问题（例如，Python中的HTTP查询）后，他们会将其打包为一个抽象且可重用的库。 将来面临类似问题的工程师可以简单地搜索现有的库，下载一个库并在自己的项目中使用它。 以类似的方式，将来，元学习系统将能够通过在高级可重用块的全局库中进行筛选来组装新程序。 当系统发现自己正在为几种不同的任务开发类似的程序子例程时，就会提出一个“抽象的”、可重用的子程序版本，并将其存储在全局库中。 这样的过程将实现抽象的能力，这是实现“极端泛化”的必要组件：可以说跨不同任务和领域有用的子例程可以“抽象”问题解决的某些方面。 “抽象”的定义类似于软件工程中的抽象概念。 这些子例程可以是geometric （具有预训练表示形式的深度学习模块），也可以是algorithmic （更接近于当代软件工程师操作的库）</p>
<h2 id="Deep-learning-in-artificial-intelligence-solid-development-amp-tricks"><a href="#Deep-learning-in-artificial-intelligence-solid-development-amp-tricks" class="headerlink" title="Deep learning in artificial intelligence: solid development &amp; tricks"></a>Deep learning in artificial intelligence: solid development &amp; tricks</h2><p>How does a deep network work?</p>
<p>• Intuitive design or theoretical foundation?</p>
<p>• Change network structure but why is a structure better than another?</p>
<p>• Adjust hyper-parameters but why are these hyper-parameters better than those?</p>
<p>• Making a prediction but what is the rationale of the prediction</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
          
            <a href="/tags/Deep-Learning/" rel="tag"><i class="fa fa-tag"></i> Deep Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/01/29/namingJava/" rel="next" title="Android项目命名">
                <i class="fa fa-chevron-left"></i> Android项目命名
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/03/07/ComputerNetwork1/" rel="prev" title="计算机网络概况">
                计算机网络概况 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">28</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/NaNillll" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#limitations"><span class="nav-number">1.</span> <span class="nav-text">limitations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-learning-the-geometric-view"><span class="nav-number">1.1.</span> <span class="nav-text">Deep learning: the geometric view</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-limitations-of-deep-learning"><span class="nav-number">1.2.</span> <span class="nav-text">The limitations of deep learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-risk-of-anthropomorphizing-machine-learning-models"><span class="nav-number">1.3.</span> <span class="nav-text">The risk of anthropomorphizing machine learning models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Local-generalization-versus-extreme-generalization"><span class="nav-number">1.4.</span> <span class="nav-text">Local generalization versus extreme generalization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Take-aways"><span class="nav-number">1.5.</span> <span class="nav-text">Take-aways</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#future"><span class="nav-number">2.</span> <span class="nav-text">future</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#main-directions"><span class="nav-number">2.1.</span> <span class="nav-text">main directions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Models-as-programs"><span class="nav-number">2.2.</span> <span class="nav-text">Models as programs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Beyond-backpropagation-and-differentiable-layers"><span class="nav-number">2.3.</span> <span class="nav-text">Beyond backpropagation and differentiable layers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Automated-machine-learning"><span class="nav-number">2.4.</span> <span class="nav-text">Automated machine learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lifelong-learning-and-modular-subroutine-reuse"><span class="nav-number">2.5.</span> <span class="nav-text">Lifelong learning and modular subroutine reuse</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-learning-in-artificial-intelligence-solid-development-amp-tricks"><span class="nav-number">2.6.</span> <span class="nav-text">Deep learning in artificial intelligence: solid development &amp; tricks</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
  
 
  
  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">42.9k</span>
  
</div>











        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  

</body>
</html>
